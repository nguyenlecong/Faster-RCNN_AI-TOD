{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modules import utils\n",
    "from modules import transforms as T\n",
    "from modules.engine import train_one_epoch, evaluate\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cython\n",
    "# !pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "\n",
    "# !git clone https://github.com/pytorch/vision.git\n",
    "\n",
    "# !cp vision/references/detection/utils.py .\n",
    "# !cp vision/references/detection/transforms.py .\n",
    "# !cp vision/references/detection/coco_eval.py .\n",
    "# !cp vision/references/detection/engine.py .\n",
    "# !cp vision/references/detection/coco_utils.py ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Modifying the model to add a different backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = torchvision.models.vgg16(weights=\"VGG16_Weights.IMAGENET1K_V1\").features\n",
    "backbone.out_channels = 512\n",
    "\n",
    "anchor_size = config.anchor_size\n",
    "anchor_ratio = config.anchor_ratio\n",
    "anchor_generator = AnchorGenerator(sizes=(anchor_size,),\n",
    "                                   aspect_ratios=(anchor_ratio,))\n",
    "\n",
    "class_map = config.class_map\n",
    "num_classes = len(class_map)\n",
    "\n",
    "min_size = config.min_size\n",
    "max_size = config.max_size\n",
    "\n",
    "box_detections_per_img = config.detections_per_img\n",
    "\n",
    "model = FasterRCNN(backbone=backbone,\n",
    "                   num_classes=num_classes,\n",
    "                   min_size=min_size,\n",
    "                   max_size=max_size,\n",
    "                   rpn_anchor_generator=anchor_generator,\n",
    "                   box_detections_per_img=box_detections_per_img\n",
    "                   )\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.PILToTensor())\n",
    "    transforms.append(T.ConvertImageDtype(torch.float))\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))  # Follow Fast R-CNN paper\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.label_root = root.replace('/hdd/thaihq/qnet_search/ori_data', '/hdd/nguyenlc/ai_training/faster_rcnn/qnet_search/correct_labels')\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
    "        # self.labels = list(sorted(os.listdir(os.path.join(self.label_root, \"labels\"))))\n",
    "        self.labels = list(sorted(os.listdir(self.label_root)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
    "        label_path = os.path.join(self.label_root, self.labels[idx])\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        with open(label_path) as file:\n",
    "            label = [line.rstrip() for line in file]\n",
    "\n",
    "        num_objs = len(label)\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for i in range(num_objs):\n",
    "            # xmin, ymin, xmax, ymax, cls = [int(j) for j in label[i].split(', ')]\n",
    "            # boxes.append([xmin, ymin, xmax, ymax])\n",
    "            xmin, ymin, width, height, cls = [int(j) for j in label[i].split(', ')]\n",
    "            boxes.append([xmin, ymin, xmin+width, ymin+height])\n",
    "            labels.append(cls-1)  #**********\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        target[\"image_name\"] = os.path.basename(img_path)[:-4]\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ratio = config.train_ratio\n",
    "# val_ratio = config.val_ratio\n",
    "# train_val_batch = config.train_val_batch\n",
    "# test_batch = config.test_batch\n",
    "\n",
    "# train_dataset = CustomDataset(root, get_transform(train=True))\n",
    "# val_test_dataset = CustomDataset(root, get_transform(train=False))\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "\n",
    "# train_num = round(train_ratio*len(train_dataset))\n",
    "# val_num = round(val_ratio*len(train_dataset))\n",
    "# indices = torch.randperm(len(train_dataset)).tolist()\n",
    "\n",
    "# train_dataset = torch.utils.data.Subset(train_dataset, indices[:train_num])\n",
    "# val_dataset = torch.utils.data.Subset(val_test_dataset, indices[train_num:train_num+val_num])\n",
    "# test_dataset = torch.utils.data.Subset(val_test_dataset, indices[train_num+val_num:])\n",
    "\n",
    "# train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_val_batch,\n",
    "#                                           shuffle=True, num_workers=4,\n",
    "#                                           collate_fn=utils.collate_fn)\n",
    "\n",
    "# val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=train_val_batch,\n",
    "#                                                shuffle=False, num_workers=4,\n",
    "#                                                collate_fn=utils.collate_fn)\n",
    "\n",
    "# len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = config.train_batch\n",
    "test_batch = config.test_batch\n",
    "\n",
    "train_dataset = CustomDataset('/hdd/thaihq/qnet_search/ori_data/train', get_transform(train=True))\n",
    "val_dataset = CustomDataset('/hdd/thaihq/qnet_search/ori_data/val', get_transform(train=False))\n",
    "test_dataset = CustomDataset('/hdd/thaihq/qnet_search/ori_data/test', get_transform(train=False))\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch,\n",
    "                                          shuffle=True, num_workers=4,\n",
    "                                          collate_fn=utils.collate_fn)\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=train_batch//2,\n",
    "                                               shuffle=False, num_workers=4,\n",
    "                                               collate_fn=utils.collate_fn)\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch,\n",
    "                                               shuffle=False, num_workers=4,\n",
    "                                               collate_fn=utils.collate_fn)\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mode = config.mode=='train'\n",
    "\n",
    "def create_folder(root, train_mode):\n",
    "    max_model = 0\n",
    "    for root, j, _ in os.walk(root):\n",
    "        for dirs in j:\n",
    "            try:\n",
    "                temp = int(dirs)\n",
    "                if temp > max_model:\n",
    "                    max_model = temp\n",
    "            except:\n",
    "                continue\n",
    "        break\n",
    "    max_model += 1\n",
    "\n",
    "    log_path = os.path.join(root, str(max_model))\n",
    "    os.makedirs(log_path)\n",
    "\n",
    "    if train_mode:\n",
    "        weight_path = os.path.join(log_path, 'weights')\n",
    "        os.makedirs(weight_path)\n",
    "    else:\n",
    "        weight_path = None\n",
    "\n",
    "    return log_path, weight_path\n",
    "\n",
    "if train_mode:\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # construct an optimizer - SGD follow Faster R-CNN paper\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=config.learning_rate, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "    # and a learning rate scheduler which decreases the learning rate by\n",
    "    # 10x every 3 epochs\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, data_loader, device):\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    \n",
    "    for images, targets in metric_logger.log_every(data_loader, print_freq=100):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) if isinstance(\n",
    "            v, torch.Tensor) else v for k, v in t.items()} for t in targets]\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            loss_dict = model(images, targets)\n",
    "            # losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "        \n",
    "    return metric_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_mode:\n",
    "    from early_stopping import EarlyStopping\n",
    "    stopper = EarlyStopping(config.patience)\n",
    "\n",
    "    log_folder, weight_folder = create_folder('training', train_mode)\n",
    "\n",
    "\n",
    "    print('Start training')\n",
    "\n",
    "    num_epochs = config.num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # train for one epoch, printing every 100 iterations\n",
    "        train_loss = train_one_epoch(model, optimizer, train_data_loader, device, epoch, print_freq=100)  # val_data_loader for debugging\n",
    "\n",
    "        train_log_path = os.path.join(log_folder, 'train_log.txt')\n",
    "        stopper.log(train_log_path, str(train_loss))\n",
    "\n",
    "        last_weight_path = os.path.join(weight_folder, 'last.pt')\n",
    "        torch.save(model, last_weight_path)\n",
    "        \n",
    "        # update the learning rate\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # evaluate on the val dataset\n",
    "        print('Start validating')\n",
    "\n",
    "        val_loss = val(model, val_data_loader, device)\n",
    "\n",
    "        val_log_path = os.path.join(log_folder, 'val_log.txt')\n",
    "        stopper.log(val_log_path, str(val_loss))\n",
    "\n",
    "        # loss = float(str(val_loss).split('  ')[0].split(' ')[1]) # for debugging\n",
    "        loss = float(str(val_loss).split('  ')[0].split(' ')[2][1:-1])  # Average\n",
    "\n",
    "        stop = stopper(epoch, round(loss, 2))\n",
    "        if stop:\n",
    "            best_weight_path = os.path.join(weight_folder, 'best.pt')\n",
    "            torch.save(model, best_weight_path)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(log_folder, mode):\n",
    "    path = os.path.join(log_folder, f'{mode}_log.txt')\n",
    "    if not os.path.exists(path):\n",
    "        return\n",
    "    \n",
    "    file = open(path, 'r')\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    if mode == 'train':\n",
    "        idx = 1  # 0 is lr\n",
    "        \n",
    "        lr = [float(str(i).split('  ')[0].split(' ')[1]) for i in lines]\n",
    "        plt.figure(figsize=(15, 10), tight_layout=True)\n",
    "        plt.plot(range(len(lr)), lr, label='learning rate')\n",
    "        plt.title('Learning rate')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        save_path = os.path.join(log_folder, f'learning_rate.png')\n",
    "        plt.savefig(save_path)\n",
    "        plt.show()\n",
    "\n",
    "    elif mode == 'val':\n",
    "        idx = 0\n",
    "\n",
    "    loss = [float(str(i).split('  ')[idx].split(' ')[2][1:-1]) for i in lines]\n",
    "\n",
    "    plt.figure(figsize=(15, 10), tight_layout=True)\n",
    "    plt.plot(range(len(loss)), loss, label='loss')\n",
    "\n",
    "    min_loss = min(loss)\n",
    "    min_index = loss.index(min(loss))\n",
    "    plt.plot(min_index, min_loss, '*', label='best value')\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    save_path = os.path.join(log_folder, f'{mode}_loss.png')\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if train_mode:\n",
    "    # log_folder = 'training/1'\n",
    "    plot(log_folder, mode='train')\n",
    "    plot(log_folder, mode='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(boxes, scores, iou_thresh=0.5):\n",
    "    return torchvision.ops.nms(boxes, scores, iou_thresh)\n",
    "\n",
    "def plot_result(image, boxes, cls, scr):\n",
    "    color = color_map[cls]\n",
    "\n",
    "    x1, y1, x2, y2 = boxes.cpu().numpy().astype(\"int\")\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color, 1)\n",
    "\n",
    "    cv2.putText(image, ' '.join([cls, scr]), (x1, y1-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1,\n",
    "                cv2.LINE_AA)\n",
    "    # cv2.putText(image, ' '.join([cls, scr]), (x1, y1-10),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 1,\n",
    "    #             cv2.LINE_AA)\n",
    "\n",
    "\n",
    "from seaborn import color_palette\n",
    "\n",
    "def make_color_map():\n",
    "    '''\n",
    "        Create a color map for each class\n",
    "    '''\n",
    "    names = sorted(set(list(class_map.keys())))\n",
    "    n = len(names)\n",
    "    cp = color_palette(\"Paired\", n)\n",
    "\n",
    "    cp[:] = [tuple(int(255*c) for c in rgb) for rgb in cp]\n",
    "\n",
    "    return dict(zip(names, cp))\n",
    "\n",
    "if not train_mode:   \n",
    "    color_map = make_color_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, img):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    # put the model in evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model([img.to(device)])\n",
    "\n",
    "    image = img.numpy().transpose(1, 2, 0)\n",
    "    image = (image*255).astype('uint8')\n",
    "\n",
    "    boxes = pred[0]['boxes']\n",
    "    scores = pred[0]['scores']\n",
    "    keep = nms(boxes, scores, 0.1)\n",
    "\n",
    "    labels = pred[0]['labels']\n",
    "    \n",
    "    scr_th = 0.2\n",
    "    for i in keep:\n",
    "        cls = list(class_map.keys())[int(labels[i])]\n",
    "        scr = round(float(scores[i]), 2)\n",
    "        \n",
    "        if scr >= scr_th:\n",
    "            plot_result(image, boxes[i], cls, str(scr))\n",
    "\n",
    "    image = image[:,:,::-1]\n",
    "    # cv2.imwrite('tmp.tif', image)\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(image[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not train_mode:\n",
    "    model_1 = torch.load('training/1/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not train_mode:\n",
    "    # pick one image from the test set\n",
    "    img, target = test_dataset[2500]\n",
    "    print(target['image_name'])\n",
    "\n",
    "    infer(model_1, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    with torch.no_grad():\n",
    "        path, _ = create_folder('predictions', train_mode)\n",
    "\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        model.eval()\n",
    "        \n",
    "        for i in tqdm(range(len(test_dataset))):\n",
    "            img, target = test_dataset[i]\n",
    "\n",
    "            img_name = target['image_name']\n",
    "            save_path = os.path.join(path, f'{img_name}.txt')\n",
    "            file = open(save_path, \"w\")\n",
    "\n",
    "            pred = model([img.to(device)])[0]\n",
    "            \n",
    "            boxes = pred['boxes']\n",
    "            scores = pred['scores']\n",
    "            labels = pred['labels']\n",
    "            \n",
    "            zip_lists = zip(labels, scores, boxes)\n",
    "\n",
    "            r = len(boxes)\n",
    "            for i, x in enumerate(zip_lists):                \n",
    "                class_name = list(class_map.keys())[int(x[0])]\n",
    "                score = round(float(x[1]), 2)\n",
    "\n",
    "                x, y, x2, y2 = x[2].cpu().numpy().astype(\"int\")\n",
    "                w = x2 - x\n",
    "                h = y2 - y\n",
    "\n",
    "                s = ' '.join(str(i) for i in [class_name, score, x, y, w, h])\n",
    "\n",
    "                if i<r-1:\n",
    "                    s += '\\n'\n",
    "\n",
    "                file.writelines(s)\n",
    "            \n",
    "            file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not train_mode:\n",
    "#     model_1 = torch.load('training/1/weights/best.pt')\n",
    "#     test(model_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afd481019de055d53831c4816760b4099e1ec54cf808b21949a4b525a6c74a9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
